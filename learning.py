# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eiq9JuPMCR6wlhrYBaqhwbVWz3STCn4W
"""

import numpy as np
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm

# Чтение данных
df_info = pd.read_csv('/content/Music Info.csv')
df_users = pd.read_csv('/content/User Listening History.csv')

df_info = df_info.dropna(subset=['tags', 'genre'], how='all')

unique_genres = df_info['genre'].dropna().unique()
unique_genres = sorted(unique_genres)
tags_to_genre = {tag.lower(): tag for tag in unique_genres}

def assign_genre_based_on_tags_case_sensitive(tags_str, existing_genres):
    if pd.notna(tags_str) and tags_str != "":
        first_tag = tags_str.split(',')[0].strip().lower()
        if first_tag in existing_genres:
            return existing_genres[first_tag]
    return "Other"

df_info['genre'] = df_info.apply(lambda row: row['genre'] if pd.notna(row['genre']) and row['genre']
                    in unique_genres else assign_genre_based_on_tags_case_sensitive(row['tags'], tags_to_genre), axis=1)

grouped_users = df_users.groupby(['user_id', 'track_id']).sum().reset_index()
df_merged = pd.merge(grouped_users, df_info, on='track_id', how='left')

sampled_users = grouped_users['user_id'].drop_duplicates().sample(frac=0.04)
df_sampled = grouped_users[grouped_users['user_id'].isin(sampled_users)]

num_test_samples = 10
test = df_sampled.groupby('user_id').tail(num_test_samples)
train = df_sampled.drop(test.index)

print(train.shape, test.shape)

interactions = (
    train
    .groupby('user_id')['track_id'].agg(lambda x: list(x))
    .reset_index()
    .rename(columns={'track_id': 'true_train'})
    .set_index('user_id')
)
interactions['true_test'] = (
    test
    .groupby('user_id')['track_id'].agg(lambda x: list(x))
)

interactions.loc[pd.isnull(interactions.true_test), 'true_test'] = [
    [''] for x in range(len(interactions.loc[pd.isnull(interactions.true_test), 'true_test']))]

ratings = pd.pivot_table(
    train,
    values='playcount',
    index='user_id',
    columns='track_id').fillna(0)

# Нормализация данных
scaler = StandardScaler()
ratings_scaled = scaler.fit_transform(ratings.values)

# Создание и обучение модели
model = Sequential()
model.add(Dense(128, input_dim=ratings_scaled.shape[1], activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(ratings_scaled.shape[1], activation='linear'))

model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error')
model.fit(ratings_scaled, ratings_scaled, epochs=50, batch_size=32, validation_split=0.1, verbose=1)

# Предсказание новых рейтингов
predicted_ratings = model.predict(ratings_scaled)
new_ratings = scaler.inverse_transform(predicted_ratings)
new_ratings_df = pd.DataFrame(new_ratings, index=ratings.index, columns=ratings.columns)

# Генерация рекомендаций
def generate_recommendations(user_track_ids, ratings, new_ratings, num_recommendations=10):
    user_preference_vector = create_preference_vector(user_track_ids, ratings.columns)

    if isinstance(new_ratings, pd.DataFrame):
        new_ratings = new_ratings.apply(pd.to_numeric, errors='coerce').fillna(0)

    if isinstance(new_ratings, pd.DataFrame):
        new_ratings = new_ratings.values

    try:
        user_predicted_ratings = np.dot(new_ratings, user_preference_vector).flatten()
        recommendations = sort_and_filter_tracks(user_predicted_ratings, user_track_ids, ratings.columns)
        return recommendations[:num_recommendations]
    except TypeError as e:
        print("Произошла ошибка:", e)

def create_preference_vector(user_track_ids, all_track_ids):
    preference_vector = np.zeros(len(all_track_ids))
    track_indices = [list(all_track_ids).index(track_id) for track_id in user_track_ids if track_id in all_track_ids]
    preference_vector[track_indices] = 1
    return preference_vector

def sort_and_filter_tracks(user_predicted_ratings, user_track_ids, all_track_ids):
    track_ratings = {track_id: rating for track_id, rating in zip(all_track_ids, user_predicted_ratings) if track_id not in user_track_ids}
    sorted_tracks = sorted(track_ratings.items(), key=lambda x: x[1], reverse=True)
    return [track[0] for track in sorted_tracks]

user_tracks = ['TRIOREW128F424EAF0', 'TRLNZBD128F935E4D8']
recommendations = generate_recommendations(user_tracks, ratings, new_ratings_df, num_recommendations=10)
print(recommendations)

# Сохранение модели и данных
model.save('recommendation_model.h5')
interactions.to_csv('interactions.csv')
ratings.to_csv('ratings.csv')
new_ratings_df.to_csv('new_ratings.csv')

# Функция вычисления Recall@K
def recall_at_k(recommendations, true_tracks, k):
    return len(set(recommendations[:k]).intersection(set(true_tracks))) / len(true_tracks)

# Вычисление метрики Recall@K
def evaluate_recall_at_k(interactions, new_ratings_df, k):
    recalls = []
    for user_id in interactions.index:
        true_test_tracks = interactions.loc[user_id, 'true_test']
        if true_test_tracks:
            user_recommendations = generate_recommendations(interactions.loc[user_id, 'true_train'], ratings, new_ratings_df, num_recommendations=k)
            recall = recall_at_k(user_recommendations, true_test_tracks, k)
            recalls.append(recall)
    return np.mean(recalls)

recall_k = 10
average_recall = evaluate_recall_at_k(interactions, new_ratings_df, recall_k)
print(f"Recall@{recall_k}: {average_recall}")